# Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks
### Abstract

1. 最先进的目标检测网络依赖于区域建议算法来假设目标位置
2. SPPnet[7]和快速R-CNN[5]等技术的进步降低了检测网络的运行时间，暴露了区域提案计算的瓶颈。
3. 在这项工作中，我们引入了一个与检测网络共享全图像卷积特性的区域建议网络(RPN)，从而实现了几乎免费的区域建议
4. RPN是一个全卷积网络，它同时预测每个位置的对象边界和对象得分
5. RPN经过端到端的训练，生成高质量的区域建议，快速R-CNN用于检测
6. 通过简单的交替优化，可以训练RPN和快速R-CNN共享卷积特征。
7. 对于非常深的VGG-16型号[19]，我们的检测系统在GPU上帧率为5fps(包括所有步骤)，同时在PASCAL VOC 2007 (73.2% mAP)和2012 (70.4% mAP)上实现了最先进的目标检测精度，每张图像使用300个提案。

## Introduction

1. 区域建议方法(如[22])和基于区域的卷积神经网络(R-CNNs)[6]的成功应用推动了目标检测领域的最新进展。
2. 虽然基于区域的CNNs的计算成本与最初在[6]中开发时一样昂贵，但是由于共享了提案之间的卷积，它们的成本已经大大降低了[7,5]。
3. 最新的版本是Fast R-CNN[5]，它使用非常深的网络[19]实现了近乎实时的速率当忽略了在区域提案上花费的时间。
4. 现在，提案是最先进的检测系统的计算瓶颈。
5. 区域建议方法通常依赖于廉价的特性和经济的推理方案
6. 选择性搜索(SS)[22]是目前最流行的一种方法，它基于工程底层特征贪婪地合并超像素
7. 然而，与高效的检测网络[5]相比，选择性搜索要慢一个数量级，在CPU实现中，每幅图像的搜索速度为2s
8. EdgeBoxes[24]目前提供了提案质量和速度之间的最佳权衡，每幅图0.2秒
9. 然而，区域建议步骤仍然消耗与检测网络相同的运行时间
10. 有人可能会注意到，快速的基于区域的CNNs利用了gpu，而研究中使用的区域建议方法是在CPU上实现的，这使得这种运行时比较不公平
11. 加速提案计算的一个明显方法是为GPU重新实现它
12. 这可能是一个有效的工程解决方案，但重新实现忽略了下游检测网络，因此错过了共享计算的重要机会
13. 在本文中，我们证明了一种基于深度网络的算法变化计算方案可以得到一个优雅而有效的解决方案，在给定检测网络计算量的情况下，方案计算几乎是免费的
14. 为此，我们引入了与最先进的目标检测网络共享卷积层的新型Region Proposal Networks(RPNs)[7,5]。
15. 通过在测试时共享卷积，计算提议的边际成本很小(例如，每张图像10ms)。
16. 我们观察到，基于区域的检测器(如Fast R-CNN)使用的卷积(conv)特征图也可以用来生成区域建议
17. 这些conv特性之上,我们构建的rpn通过添加两个额外的conv层:一个编码每个conv map位置映射到一个短的(例如,256 - d)特征向量和第二个,在每个conv map位置,输出一个客体性分数和退化边界k地区建议在这个位置相对于各种尺度和纵横比(k = 9是一个典型的值)。
18. 因此，我们的RPNs是一种全卷积网络(FCN)[14]，它们可以被端到端的训练，专门用于生成检测建议的任务。
19. 为了将RPNs与Fast R-CNN[5]目标检测网络相结合，我们提出了一种简单的训练方案，在保持方案不变的情况下，在区域建议任务的微调和目标检测的微调之间交替进行。
20. 该方案收敛速度快，生成了一个具有conv特性的统一网络，并在两个任务之间共享。
21. 我们在PASCAL VOC检测基准[4]上对我们的方法进行了评估，其中使用RPNs的 Fast R-CNNs比选择性搜索的Fast R-CNNs的强基线具有更好的检测精度。
22. 同时，我们的方法在测试时几乎免除了SS的所有计算负担，提案的有效运行时间只有10毫秒
23. 使用非常昂贵的[19]非常深的模型，我们的检测方法在GPU上仍然有5fps的帧率(包括所有步骤)，因此在速度和精度上都是一个实用的对象检测系统(PASCAL VOC 2007上的73.2% mAP和2012年的70.4% mAP)。

## Related Work

1. 最近有几篇论文提出了使用深度网络来定位特定于类或与类无关的边界框的方法[21、18、3、20]
2. 在OverFeat方法[18]中，训练一个全连接(fc)层来预测假定为单个对象的定位任务的框坐标
3. 然后将fc层转换为conv层，用于检测多个类特定的对象
4. 多盒方法[3,20]从一个网络中生成区域建议，该网络的最后一个fc层同时预测多个(如800个)盒子，用于R-CNN[6]对象检测
5. 他们的建议网络应用于单个图像或多个大型图像作物(例如，224x224)[20]。
6. 稍后，我们将在上下文中使用我们的方法更深入地讨论OverFeat和MultiBox。
7. 卷积的共享计算[18、7、2、5]因其高效、准确的视觉识别而受到越来越多的关注。
8. OverFeat论文[18]从图像金字塔中计算conv特征，用于分类、定位和检测
9. 提出了一种基于共享conv特征映射的自适应大小池(SPP)[7]，用于高效的基于区域的目标检测[7,16]和语义分割[2]。
10. Fast R-CNN[5]支持端到端检测器的共同conv功能的培训，并显示了惊人的准确性和速度

## Region Proposal Networks

1. Region Proposal Network(RPN)以图像(任何大小)作为输入和输出一组矩形对象建议，每个建议都有一个对象得分

2. 我们用一个全卷积网络[14]对这个过程建模，我们将在本节中对此进行描述

3. 因为我们的最终目标是与一个Fast R-CNN对象检测网络[5]共享计算，所以我们假设这两个网络共享一组公共的conv层

4. 在实验中，我们研究了具有5个可共享conv层的Zeiler和Fergus模型[23](ZF)，以及具有13个可共享conv层的Simonyan和Zisserman模型[19] (VGG)。

5. 为了生成区域建议，我们在最后一个共享conv层输出的conv feature map上滑动一个小网络。

6. 该网络完全连接到输入conv特征图的一个n x n空间窗口。

7. 每个滑动窗口被映射到一个低维向量(256-d表示ZF, 512-d表示VGG)。

8. 这个向量被输入到两个同级完全连接的层—box-regression层(reg)和box-classification层(cls)。

9. 我们在本文中使用n = 3，注意到输入图像上的有效接收域很大(ZF和VGG分别为171和228像素)。

10. 图1(左)中的一个位置显示了这个微型网络。

11. 注意，由于微型网络以滑动窗口的方式运行，因此所有空间位置都共享完全连接的层

12. 这种体系结构很自然地使用一个n xn conv层实现，然后是两个同级的1 x1 conv层(分别用于reg和cls)。

13. ReLUs[15]应用于nxn conv层的输出。

    #### Translation-Invariant Anchors

    1. 在每个滑动窗口位置，我们同时预测k个区域的建议
    2. 在每个滑动窗口的位置,我们同时预测k地区建议,所以reg层4 k输出编码k框的坐标
    3. cls层输出2k分，用于估计每个提案的目标/非目标概率
    4. k个建议相对于k个参考框(称为anchor)进行参数化
    5. 每个锚都以所讨论的滑动窗口为中心，并与比例和纵横比相关联
    6. 我们使用3个尺度和3个纵横比，在每个滑动位置产生k = 9个锚
    7. 小为wxh(通常为2400)的conv feature map，总共有一个whk锚。
    8. 我们的方法的一个重要特性是它是平移不变的，无论是在锚点方面，还是在计算相对于锚点的建议的函数方面
    9. 作为比较，MultiBox[20]使用k-means生成800个锚点，这些锚点不是平移不变的。
    10. 如果一个人转化了图像中的一个对象，那么这个建议就应该转化，并且相同的函数应该能够在任何位置预测这个建议
    11. 此外，由于多框锚不是平移不变的，它需要(4+1)x800维的输出层，而我们的方法需要(4+2)x9维的输出层。
    12. 我们的提案层参数少了一个数量级(使用GoogLeNet[20]的多盒参数为2700万个，而使用VGG-16的RPN参数为240万个)，因此在PASCAL VOC这样的小数据集中过度拟合的风险更小

    #### A Loss Function for Learning Region Proposals

    1. 对于训练rpc，我们为每个锚分配一个二进制类标签(对象或非对象)

    2. 我们给两种锚分配了一个积极的标签:(i)相交过并集(IoU)最高的锚与地面真值框重叠，或(ii) IoU与任何地面真值框重叠大于0.7的锚。

    3. 请注意，一个ground-truth框可以为多个锚分配积极的标签

    4. 如果所有ground-truth框的IoU比率都低于0.3，我们将负标签分配给非正锚

    5. 既不积极也不消极的锚对培训目标没有帮助。

    6. 利用这些定义，我们最小化了快速RCNN[5]中多任务丢失后的目标函数。

    7. 图像的损失函数定义为：
       $$
       L（\{p_i\},\{t_i\}） = (1/N_{cls})\sum_i L_{cls}(p_i, p_i^*)+\lambda(1/N_{reg})\sum_i p_i^*L_{reg}(t_i, t_i^*)
       $$
       

    8. 这里，i为小批量锚的指标，pi为预测锚i为对象的概率。

    9. 如果锚为正，则ground-truth标签$p_i^*$为1，如果锚为负，则为0

    10. $t_i$ 是表示预测边界框的4个参数化坐标的向量，$t_i^*$是与一个正锚关联的ground-truth框的参数化坐标。

    11. 分类损失Lcls是两个类(对象和非对象)的log损失。

    12. 对于回归损失，我们使用$L_{reg} (t_i,t_i^*) = R (t_i-t_i^*)$其中R是健壮的损失函数(光滑L1)[5]中定义。

    13. 术语$p_i^* L_{reg}$表示回归损失仅在正锚点$(p_i^* = 1)$被激活，否则将被禁用$(p_i^* = 0)$。

    14. cls层和reg层的输出分别由$\{p_i\}$和$\{t_i\}$组成

    15. 这两项用$N_{cls}$和$N_{reg}$以及一个配重$\lambda^3$来标准化

    16. 回归时，我们采用[6]以下4个坐标的参数化:
        $$
        t_x = (x-x_a)/w_a, \quad t_y = (y-y_a)/h_a, \quad t_w = log(w/w_a), \quad t_h = log(h/h_a)
        $$

        $$
        t_x^* = (x^*-x_a)/w_a, \quad t_y^* = (y^*-y_a)/h_a, \quad t_w^* = log(w^*/w_a), \quad t_h^* = log(h^*/h_a)
        $$

    17. 其中x、y、w和h表示盒子中心、宽度和高度的两个坐标

    18. 变量x、xa和x*分别表示预测框、锚框和地面真值框(同样，y;w;h)。

    19. 这可以被看作是从锚框到附近的ground-truth框的边界盒回归。

    20. 然而，与以往基于特征图的方法[7,5]不同，我们的方法实现了边界盒回归。

    21. 在[7,5]中，对任意大小区域汇集的特征进行边界盒回归，回归权重由所有区域大小共享

    22. 在我们的公式中，用于回归的特征在特征图上具有相同的空间大小(n x n)。

    23. 为了适应不同的尺寸，我们学习了一组k个边界盒回归器。

    24. 每个回归因子负责一个尺度和一个纵横比，而k个回归因子不共享权重

    25. 因此，即使特性具有固定的大小/比例，仍然可以预测各种大小的盒子。

    #### Optimization

    1. RPN是一个自然实现的全卷积网络[14]，可以通过反向传播和随机梯度下降(SGD)[12]进行端到端训练。
    2. 我们采用[5]的“图像中心”采样策略来训练这个网络
    3. 每个小批都来自一个包含许多正面和负面锚的图像
    4. 所有锚点的损失函数都是可以优化的，但这将偏向于负样本，因为负样本占主导地位。
    5. 相反，我们在一张图像中随机抽取256个锚点来计算一个小批量的损失函数，其中抽样的正锚点和负锚点的比例高达1:1。
    6. 如果一个图像中有少于128个阳性样本，我们用阴性样本填充小批。
    7. 我们随机初始化所有的新层从一个零均值高斯分布与标准差0.01的权重
    8. 所有其他层(即和标准实践[6]一样，通过对ImageNet分类[17]的模型进行预训练初始化共享conv层。
    9. 我们对ZF网的所有层进行调优，并对VGG网进行conv31和up调优，以保存内存[5]。
    10. 在PASCAL数据集中，60k个小批使用0.001的学习率，接下来的20k个小批使用0.0001
    11. 我们还使用了0.9的动量和0.0005[11]的重量衰减。
    12. 我们的实现使用了Caffe[10]。

    #### Sharing Convolutional Features for Region and Object Detection

    1. 到目前为止，我们已经描述了如何训练一个用于区域建议生成的网络，而不考虑将利用这些建议的基于区域的对象检测CNN
    2. 对于检测网络，我们采用了快速R-CNN[5]4，现在描述了一种学习RPN和快速R-CNN之间共享的conv层的算法。
    3. RPN和快速R-CNN都是独立训练的，它们将以不同的方式修改conv层
    4. 因此，我们需要开发一种技术，允许在两个网络之间共享conv层，而不是学习两个独立的网络
    5. 注意，这并不像简单地定义一个包含RPN和快速R-CNN的单一网络，然后通过反向传播联合优化它那么容易
    6. 究其原因，Fast R-CNN训练依赖于固定的对象建议，在学习Fast R-CNN的同时改变建议机制是否会收敛，目前尚不清楚先验。
    7. 虽然这种联合优化是未来工作中一个有趣的问题，但我们开发了一个实用的四步训练算法，通过交替优化学习共享特性。
    8. 在第一步中，我们如上所述训练RPN。
    9. 此网络初始化为ImageNet预训练模型，并为区域建议任务端到端进行微调
    10. 第二步，利用step-1 RPN生成的方案，利用快速R-CNN训练一个独立的检测网络。
    11. 该检测网络也由imagenet预训练模型初始化。
    12. 此时，两个网络不共享conv层。
    13. 在第三步中，我们使用检测器网络初始化RPN训练，但是我们修复了共享的conv层，只微调了RPN特有的层
    14. 现在这两个网络共享conv层
    15. 最后，保持共享conv层固定，我们微调快速R-CNN的fc层。
    16. 因此，两个网络共享相同的conv层，形成统一的网络。

    #### Implementation Details

    1. 我们在单尺度图像上训练和测试区域建议和目标检测网络[7,5]。
    2. 我们重新缩放图像，使其较短的一面是s = 600像素[5]。
    3. 多尺度特征提取可以提高精度，但不能很好地权衡[5]的速度精度。
    4. 我们还注意到，对于ZF和VGG网，在重新缩放的图像上，最后一个conv层的总步幅为16个像素，因此在一个典型的PASCAL图像(~500x375)上为~10个像素。
    5. 即使是如此大的步幅也能提供良好的结果，尽管更小的步幅可能会进一步提高准确性。
    6. 对于锚点，我们使用了3种尺度，盒子区域为128^2  、256^2 和 512^2  像素，长宽比为1:1、1:2和2:1。
    7. 我们注意到，在预测大型提案时，我们的算法允许使用比基础接受域更大的锚框
    8. 这样的预测并非不可能——如果一个物体的中心是可见的，那么人们仍然可以粗略地推断出这个物体的范围。
    9. 通过这种设计，我们的解决方案不需要多尺度特征或多尺度滑动窗口来预测大面积，节省了大量的运行时间。
    10. 图1(右)显示了我们的方法对大范围的尺度和纵横比的能力。
    11. 下表显示了每个使用ZF net的锚的学习平均建议大小(s = 600的数字)。
    12. 需要小心处理跨越图像边界的锚框。
    13. 在培训过程中，我们忽略了所有的跨界锚点，以免造成损失。
    14. 对于一个典型的1000x600图像，总共大约有20k (60x40x9)个锚。
    15. 忽略跨界锚点后，每幅图像约有6k个锚点用于训练。
    16. 如果训练中不忽略跨界离群点，则会在目标中引入较大且难以纠正的误差项，训练不收敛。
    17. 然而，在测试过程中，我们仍然对整个图像应用全卷积RPN。这可能会生成跨边界的建议框，我们将其剪辑到图像边界。
    18. 一些RPN建议彼此高度重叠
    19. 为了减少冗余，我们根据提案区域的cls评分对提案区域采用非最大抑制(NMS)。
    20. 我们将NMS的IoU阈值设置为0.7，这样每个图像的建议区域大约为2k
    21. 正如我们将展示的，NMS不会损害最终的检测精度，但会大大减少提案的数量。
    22. 在NMS之后，我们使用排名前n的建议区域进行检测
    23. 在接下来的测试中，我们使用2k RPN提案训练快速的R-CNN，但是在测试时评估不同数量的提案

    ## Experiments

    1. 我们在PASCAL VOC 2007检测基准[4]上对我们的方法进行了综合评价。
    2. 该数据集由约5k个训练图像和5k个测试图像组成，包含20多个对象类别。
    3. 我们还在PASCAL VOC 2012基准测试中提供了一些模型的结果
    4. 对于ImageNet预训练网络，我们使用ZF net[23]的“快速”版本，它有5个conv层和3个fc层，公共VGG-16模型5[19]有13个conv层和3个fc层
    5. 我们主要评估检测平均精度(mAP)，因为这是用于对象检测的实际度量(而不是关注对象建议代理度量)。
    6. 表1 (top)显示了使用不同区域建议方法训练和测试时快速的R-CNN结果。
    7. 这些结果使用ZF网络。
    8. 对于选择性搜索(SS)[22]，我们通过“快速”模式生成约2k个SS提案。
    9. 对于EdgeBoxes (EB)[24]，我们使用调优为0.7 IoU的缺省EB设置生成建议。
    10. SS和EB的mAP值分别为58.7%和58.6%。
    11. RPN与快速R-CNN实现了竞争的结果，与地图59.9%，而使用多达300个提案。
    12. 由于共享conv计算，使用RPN比使用SS或EB产生更快的检测系统;提案越少，区域fc成本也越低。
    13. 接下来，我们考虑了RPN的几种烧蚀，并证明了在使用非常深的网络时，提案质量得到了提高。
    14. **Ablation Experiments**.为了研究RPNs的行为，我们进行了几项消融研究。
    15. 首先，我们展示了在RPN和快速R-CNN检测网络之间共享conv层的效果。
    16. 为此，我们在四步训练过程的第二步之后停止。
    17. 使用单独的网络将结果略微降低到58.7% (RPN+ZF, unshared，表1)。
    18. 我们观察到，这是因为在第三步中，当检测调谐特性用于微调RPN时，提案质量得到了提高。
    19. 其次，分析了RPN对训练快速R-CNN检测网络的影响。
    20. 为此，我们利用2k SS方案和ZF网络训练了一个快速的R-CNN模型。
    21. 我们修正了这个检测器，并通过改变测试时使用的建议区域来评估检测图。
    22. 在这些烧蚀实验中，RPN与探测器没有共同的特征。
    23. 在测试时用300个RPN提案替换SS，得到56.8%的mAP。
    24. mAP中的损失是由于培训/测试建议之间的不一致
    25. 这个结果作为以下比较的基线。
    26. 有些令人惊讶的是，当在测试时使用排名前100的提案时，RPN仍然会导致竞争结果(55.1%)，这表明排名前100的提案是准确的
    27. 在另一个极端，使用排名最高的6k RPN建议(不使用NMS)有一个类似的mAP(55.2%)，这表明NMS不会损害检测mAP，并可能减少错误警报。
    28. 接下来，我们通过在测试时关闭RPN的cls和reg输出，分别研究它们的作用。
    29. 当在测试时去掉cls层(因此不使用NMS/rank)，我们从未得分区域随机抽取N个提案。
    30. N = 1k时，mAP几乎没有变化(55.8%)，但当N = 100时，mAP下降到44.6%。
    31. 这表明，cls评分说明了排名最高的提案的准确性。
    32. 另一方面，当reg层在测试时被移除时(因此提案变成了锚框)，mAP下降到52.1%。
    33. 这表明高质量的提案主要是由于回归的存在。
    34. 仅靠锚箱是不够精确检测的
    35. 我们还评估了更强大的网络对RPN提案质量的影响
    36. 我们使用VGG-16训练RPN，仍然使用上面的SS+ZF检测器。
    37. 该地图从56.8%(使用RPN+ZF)提高到59.2%(使用RPN+VGG)。
    38. 这是一个有希望的结果，因为它表明RPN+VGG的提案质量优于RPN+ZF。
    39. 这是一个有希望的结果，因为它表明RPN+VGG的提案质量优于RPN+ZF。由于RPN+ZF方案与SS相比具有一定的竞争力(两者用于培训和测试的一致性均为58.7%)，我们可以预期RPN+VGG优于SS。
    40. 下面的实验证明了这个假设
    41. **Detection Accuracy and Running Time of VGG-16.**
    42. 表2显示了VGG-16用于提案和检测的结果。
    43. 使用RPN+VGG，未共享特征的快速R-CNN结果为68.5%，略高于SS基线
    44. 如上所示，这是因为RPN+VGG生成的提案比SS更准确
    45. 与预先定义的SS不同，RPN是经过积极训练的，并且受益于更好的网络
    46. 对于功能共享的版本，结果是69.9%—比强大的SS基线好，但是几乎没有成本
    47. 在[5]之后，在PASCAL VOC 2007 trainval和2012 trainval的联合集上进一步训练RPN和检测网络。
    48. 该mAP为73.2%。
    49. 在PASCAL VOC 2012测试集上(表3)，我们的方法在VOC 2007 trainval+test和VOC 2012 trainval的联合集上训练的mAP为70.4%，跟随[5]。
    50. 在表4中，我们总结了整个对象检测系统的运行时间
    51. 根据内容的不同，SS需要1-2秒(平均1.51秒)，而带有VGG-16的快速R-CNN在2k SS提案上需要320毫秒(如果在fc层[5]上使用SVD，则需要223毫秒)。
    52. 我们的VGG-16系统在方案和检测上总共花费了198ms。
    53. 由于共享了conv特性，仅RPN就只需要10ms就可以计算额外的层。
    54. 由于提案较少(300份)，我们的区域计算也很低。
    55. 在ZF网络中，我们的系统帧速率为17帧。
    56. **Analysis of Recall-to-IoU.**
    57. 接下来，我们在和ground-truth boxes不同的IoU比例下计算proposal的recall
    58. 值得注意的是，Recall-to-IoU度量与最终检测精度的关系非常松散[9,8,1]。
    59. 使用这个度量来诊断建议方法比评估建议方法更合适。
    60. 在图2中，我们展示了使用300、1k和2k提案的结果。我们与SS和EB进行了比较，基于这些方法产生的置信度，N个建议是排名前N的
    61. 从图中可以看出，当提案数量从2k下降到300时，RPN方法表现得很好。
    62. 这就解释了为什么RPN在使用300个提案时就有一个很好的最终检测图。
    63. 正如我们之前分析过的，这个特性主要归因于RPN的cls项。
    64. 当提案数量较少时，SS和EB的recall比RPN下降得更快
    65. **One-Stage Detection vs. Two-Stage Proposal + Detection.**
    66. OverFeat论文[18]提出了一种利用回归器和分类器对conv特征图上的滑动窗口进行检测的方法
    67. OverFeat是一个单级的、特定于类的检测管道，而我们的是一个由不确定类的提议和特定于类的检测组成的两级级联
    68. 在OverFeat中，区域上的特征来自一个尺度金字塔上的一个宽高比滑动窗口。
    69. 这些特征用于同时确定对象的位置和类别
    70. 在RPN中，特征来自正方形(3x3)滑动窗，并预测了与不同尺度和长宽比的锚相关的建议
    71. 虽然这两种方法都使用了滑动窗口，但区域建议任务只是RPN +快速r - cn的第一个阶段，检测器负责对建议进行细化。
    72. 在我们的级联的第二阶段，从更忠实地覆盖区域特性的建议框中自适应地汇集区域方面的特性[7,5]。
    73. 我们相信这些特征会导致更精确的探测。
    74. 为了比较单级和两级系统，我们通过单级快速R-CNN仿真了OverFeat系统(从而也规避了实现细节上的其他差异)
    75. 在这个系统中，“提案”是3个尺度(128,256,512)和3个纵横比(1:1,1:2,2:1)的密集滑动窗口。
    76. 快速的R-CNN被训练来预测特定class的分数，并从这些滑动窗口返回框的位置
    77. 由于超专长系统使用图像金字塔，我们也使用从5个尺度提取的conv特征进行评估。我们使用这5种量表，如[7,5]。
    78. 表5比较了两级系统和一级系统的两种变体。
    79. 使用ZF模型，一级系统的mAP为53.9%。
    80. 这比两级系统(58.7%)低4.8%。
    81. 该实验验证了级联区域建议和目标检测的有效性。
    82. 类似的观察也在文献[5,13]中有报道，在这两篇文献中，用滑动窗口替换SS区域的提议导致了6%的退化
    83. 我们还注意到，一阶段制度较慢，因为它有更多的建议要处理。

    ## Conclusion

    1. 为了高效、准确地生成区域建议，我们提出了区域建议网络(RPNs)。
    2. 通过与下游检测网络共享卷积特性，区域建议步骤几乎是免费的。
    3. 我们的方法使一个统一的，基于深度学习的目标检测系统运行在5-17帧每秒。
    4. 学习的RPN还提高了区域建议质量，从而提高了总体目标检测精度。

    