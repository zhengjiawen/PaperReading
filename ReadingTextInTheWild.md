1. 我们在实验中暴露了管道各个部分的性能，表明了随着模型的复杂程度和高阶信息的加入，我们可以保持初始方案阶段的高召回率，同时逐步提高精度。
2. 检测阶段的召回率明显高于以往的文本检测方法，单词识别阶段的正确率高于所有之前的方法。
3. 结果是一个端到端的文本识别系统，在很大程度上超过了以前的所有方法。
4. 我们将会对注释任务进行演示（本地化和识别图像中的文本）在大量标准文本识别数据集，以及标准数据集的检索场景（检索包含查询字符串文本的图像的排序列表）。
5. 另外，我们的框架在一个真实世界的应用中得到进一步的演示，这个应用程序为用户给的查询文本即时搜索数千小时的归档新闻片段。
6. 下一个部分概述了我们的pipeline。然后我们在第3部分中回顾了一些相关的工作，第4-7节介绍了pipeline的各个阶段。我们详细地测试了我们pipeline的所有元素，包括数据集和实验设置的细节。最后，第9节是概括和总结。
7. 我的单词识别框架最初是作为技术报告出现在NIPS2014深度学习和表示学习（Representation Learning）研讨会上，以及其他一些非基于字典的变体出现的。
8. 为了识别和排名提案，我们同时训练一个很大的CNN在整个提案区域来执行文字识别，不同于以往的基于字符分类器的系统。
9. 这个网络用一个人工文本生成引擎来生成训练数据，不需要人为打上标签。
10. 分析我们管道的各个阶段，我们自始至终展示了最先进的性能。
11. 我们通过对许多E2E的文本定位基准和基于文本的图像检测数据集进行了严格的实验，比起所有以前的方法展示了巨大的提升。
12. 最后，我们展示了一个我们文字识别系统的实际应用，允许通过文本查询立即检索数千小时的新闻片段



## Introduction

1. 自然图像中文本的自动检测和识别——文本识别，是视觉理解中的一个很重要的挑战。
2. 文本作为语言的物理化身，是保存和交流信息的基础工具。
3. 现代世界上很多东西被设计为通过标签和文本线索来解释，所以文本散步在很多图片和视频中。
4. 通过文本识别，视觉媒体中的语义内容的很重要的部分可以被解码和使用，比如，可以了解、注解和检索每天生成的数十亿消费者的照片。
5. 传统的，文本定位主要集中在文档图像上，OCR技术非常适合与数字化平面的纸质文档。
6. 然而，当这些技术应用到自然环境图片时，这些文档OCR技术失败了，因为他们被调整为主要用在黑白的，基于行的打印文档环境中。
7. 这些出现在自然环境图片中的文本在外表和布局上变化很大，被大量的字体和样式绘制，存在着不一致的灯光、遮挡、方向、噪声，此外，背景对象的存在会导致虚假的假阳性检测。
8. 这里将文本定位作为一个独立的，比文档OCR更加有挑战性性的问题
9. 在过去的十年中，计算机视觉技术强有力的增长和图像的大量产生使得文本定位技术快速发展。
10. 为了更有效率地执行文本识别，大多数方法遵循将任务一分为二的直观过程：文本检测和单词识别。
11. 文本识别涉及到生成候选字符或者文字区域检测，文字识别接受这些建议并推断所描述的词。
12. 在这篇paper中，我们提出了文本定位的方法，作为其中的一部分， 做了一些关键的贡献。
13. 我们的主要贡献是一种**新颖的文本识别方式**——这是一种以深度CNN的模式，他以全词图像作为网络的输入。
14. 从图像中逐渐汇集证据，在一个巨大的字典中进行分类，比如本文在一个90k的字典中评估。
15. 非常显著地，我们的模型**纯粹基于合成的数据**，没有人为打标签的成本。
16. 我们也提出一种**增量式学习方法**来成功训练这么一个有大量类的模型。
17. 我们的识别框架异常强大，在没有使用任何真实世界标记的训练数据的情况下，实际上在现实场景的文本识别上大大超过了以前的水平。
18. 我们的第二个贡献是一种新颖的文本检测策略：使用**快速区域建议方法**执行单词检测
19. 我们使用**对象无关区域提议方式**和滑动窗口检测器的组合。
20. 这提供了非常高的单个词的bounding boxes的召回率（recall）,导致了在ICDAR 2003和有可管理的提议数量的Street View文本数据集上有98%的词召回率。
21. 假阳性（False-positive）候选词的bounding boxes使用更强的随机森林分类器（random forest classifier）进行过滤，其余的建议调整使用一个CNN训练回归bounding box坐标。
22. 我们的第三个贡献时将我们的pipeline应用于视频中文本的大规模检索。
23. 在极短的时间内，我们可以从一个大型的包含用户给定文本查询的可视化呈现的语料库中检索图像和视频，而且有非常高的精度（precision）.



## Overview of the Approach

1. 我们的方法分为以下几个阶段：**生成文本框提案、提案过滤和调整、文本识别和具体任务的最终合并**。整个过程如图所示。

2. 我们的过程大致遵循检测/识别分离——单词检测阶段之后是一个单词识别阶段

3. 然而，这两个阶段并不是完全不同的，当我们使用单词识别中获得的信息进行归并，最后对检测结果进行排序，从而形成一个更强大的整体性的文本识别系统。

4. 我们pipeline的检测阶段是基于**弱而快速的检测方法**来生成字框建议

5. 这借鉴了**Girshick et al.(2014)的R-CNN对象检测框架**的成功，该框架将区域提案映射到一个固定的大小，用于CNN识别

6. 区域建议的使用避免了评估一个穷尽多尺度的昂贵分类器，多方面比滑动窗口的搜索的计算复杂度

7. 我们使用了**Edge Box proposals(Zitnick and Dollar2014)**和训练有素的**aggregate channel features detector(Dollar et al. 2014)**(聚合通道特征检测器)生成候选词包围框。

8. 由于大量的假阳性（false-positive）建议，我们使用一个随机森林分类器来过滤建议的数量到一个可管理的规模——这是一个比起这些发现再建议算法更强大的分类器。

9. 最后，受**DPM**和**R-CNN**中bounding box回归成功的启发，我们从提案算法的种子中回归出更准确的bounding box，大大提高了阳性检测（positive detection）和**groundtruth**的平均重叠率（average overlap ratio）

10. 然而，与Felzenszwalb等人的线性回归函数不同，我们特别地训练了一个CNN来回归。我们将在每个部分中讨论这些设计选择。

11. 框架的第二个阶段为检测阶段生成的每个提案生成一个文本识别结果。

12. 我们采用全词识别方法，提供单词的整个剪裁区域作为输入输入到CNN。

13. 我们提出一个字典模型，该模型将识别任务作为一种跨90k可能性单词的字典的多路分类任务。

14. 由于这种规模的分类任务需要大量的训练数据，这个模型都是纯粹使用合成数据训练的。

15. 我们的合成数据引擎能够呈现足够逼真和可变的单词图像样本，模型在这些转换到现实世界的单词图像领域数据上训练，提供最先进的识别正确率。

16. 最后，我们使用从识别中收集到的信息，对检测结果进行多轮非极大抑制（non-maximal suppression）和bounding box回归。

    ## Related Work

    ### Text Detection Methods

    1. 文本检测方法解决了标准文本检测管道[11]的第一个任务:在自然场景图像中生成单词的分割或包围框。
    2. 检测噪声和杂乱图像中的单词实例是一项非常重要的任务，为了解决这个问题开发的方法是基于字符区域（character regions）或者滑动窗口(sliding windows)的。
    3. 字符区域方法的致力于将像素分割为字符，然后将字符分组为单词。
    4. Epshtein等人通过笔划宽度变化（SWT）找到输入图像中笔划宽度恒定的区域——两条平行边之间的距离
    5. 直观上，字符是笔画宽度相近的区域，所以像素聚类形成字符，字符基于几何启发式组合组成单词
    6. 在[44]这篇论文中，Neumann和Matas重新讨论了字符表示为笔画的概念，并使用梯度过滤器代替SWT检测有方向的笔画。比起笔划宽度恒定的区域，Neumann和matas使用极值区域作为字符区域。
    7. 黄等人，结合了一个强大的CNN分类器来有效地修剪极值区域的树，从而减少假阳性（False-positive）检测，扩展了极大稳定极值区域的使用。
    8. 滑动窗口方法（sliding windows method）将文本检测作为一种经典的目标检测任务。
    9. Wang等人使用随机蕨类分类器对滑动窗口场景中的HOG特征进行训练，寻找图像中的字符。
    10. 这些词是用小的固定词汇的象形结构框架组合形成的词。
    11. Wang&Wu等人证明了经字符分类训练的CNN可以作为有效的投影滑动窗口分类器。
    12. 在我们的一些早期工作中，我们使用CNN训练一个用于滑动窗口评估的文本/非文本分类器来做文本检测，并且也使用字符和双字母组合的CNN来进行文本识别。
    13. 我们发现，对于不同的分类任务，似乎用跨越所有CNN的特征共享比单独训练每个分类器能训练出更为强大的分类器用于文本检测
    14. 与以前的方法不同，我们的框架以低精度（low-precision），高召回率（high-recall）的方式运行——而不时使用单个单词区域建议，我们通过管道的几个阶段携带了足够多的候选项。
    15. 我们使用高召回率的区域建议方法和过滤阶段进一步完善这些。
    16. 事实上，我们的“检测方法”是在对每一个剩余的提案进行全文识别后才完成的，然后我们识别阶段的输出对提案进行归并和排序，给出最终的检测结果，并于它们的识别结果一起完成。

    ### Text Recognition Methods

    1. 文本识别的目的是得到单个单词的裁剪图像，并且识别这个单词图像。
    2. 虽然之前有很多工作专注于手写或者历史文档识别，但由于文档中没有呈现高度变化前景和背景纹理，这些方法在功能上不能推广到通用场景文本。
    3. 对于**场景文本识别**（scene text recognition）,方法可以分为两组——**基于字符的识别**（character based recognition）和**全字识别**（whole word based recognition）
    4. 基于字符的识别依赖于单个字符分类器对于每个字符进行识别，该分类器集成在单词图像中生成完整的单词识别。
    5. Yao等人2014年的论文中，通过对字符的子块进行聚类，学习了一组中层特征（mid-level features），利用霍夫投票（Hough voting）检测字符，利用作用于strokelet和HOG特征的随机森林分类器识别字符。
    6.  Alsharif and Pineau (2014), Bissacco et al. (2013), Jaderberg et al. (2014), Wang et al. (2012) 等人的做法都是使用CNNs作为字符分类器。
    7. Bissacco et al.(2013)和Alsharif and Pineau(2014)等人通过非监督二值化技术（unsupervised binarization technique）或监督分类器（supervised classifier）将单词图像过度分割成潜在的字符区域。
    8. Alsharif和Pineau(2014)将分段校正（segmentation-correction）和字符识别CNNs与固定词汇的**HMM**复杂结合，生成最终的识别结果。
    9. PhotoOCR系统利用神经网络分类器作用于片段的HOG特征作为评分，利用**波速搜索**（beam search）找到片段的最佳组合。
    10. 波速搜索结合了强 N-gram语言模型，最终的波速搜索方案通过进一步的语言模型和形状模型重新排序。
    11. 我们自己之前的工作使用二进制本文/无文本分类器（text/no-text classifier）,字符分类器，和在单词图像中密集计算的双字母组分类器（bigram classifier）的组合，作为在固定词汇上下文中**Viterbi**评分函数的提示。
    12. 作为一种可选择的词识别方法，其他方法使用全词识别，在进行词分类之前从整个子图像中汇集特征。
    13. Mishra et al.(2012)和Novikova et al.(2012)的作品仍然依赖于显式的字符分类器，但构建了一个图形来推断单词，汇集了完整的单词证据。
    14. Goel et al.(2013)通过对比简单的黑白字体渲染词，利用整词子图像特征（whole word sub-image feature）识别词。
    15. Rodriguez-Serrano et al.(2013)使用聚合的Fisher向量(Perronnin et al. 2010)和一个结构化的SVM框架来创建一个联合的单词图像(joint word-image)和文本嵌入(text embedding)。
    16. Almazan et al.(2014)进一步探讨了单词嵌入的概念，为单词图像和单词字符串的表示创建了一个联合嵌入空间。
    17. 这在Gordo(2014)中得到了扩展，Gordo明确使用字符级别的训练数据来学习中级特征.
    18. 这使得性能与(Bissacco et al. 2013)持平，但只使用了少量的培训数据。
    19. (Goodfellow et al. 2013)在不进行全场景文本识别(full scene text recognition)的情况下，利用具有多个位置敏感字符分类器(multiple position-sensitive character classifier)输出的CNN进行街道编号识别取得了很大的成功.
    20. 该模型被扩展到长达8个字符的CAPTCHA序列，在这些序列中，使用合成问题(生成模型已知)的合成训练数据显示了令人印象深刻的性能。
    21. 相反，我们展示了合成训练数据可以用于真实数据问题(生成模型未知)。
    22. 我们的文本识别方法也遵循一种全词图像方法。
    23. 与Goodfellow et al.(2013)类似，我们将单词图像作为输入到深度CNN，但是我们使用的是字典分类模型。
    24. 识别是通过对整个潜在单词字典进行多路分类来实现的。
    25. 在下面的部分中，我们将描述文本定位管道的每个阶段的细节。
    26. 这些部分按它们在端到端系统中的使用顺序给出。

    ### Proposal Generation

    1. 第一阶段是生成文本边界区域

    2. 这就是单词检测——在一个理想的场景中，我们将能够生成具有高回忆率和高精度的单词边界框，这是通过从每个边界框候选者中提取尽可能多的信息来实现的。

    3. 然而，在实践中，为了降低计算复杂性，需要对精度/召回进行权衡。

    4. 考虑到这一点，我们选择了一个快速、高回忆率的初始阶段，使用计算成本低廉的分类器，并逐渐合并更多的信息和更复杂的模型，通过拒绝导致级联的假阳性检测来提高精度

    5. 为了计算检测场景中的调用和精度，如果边界框与定义的阈值之上的地面真实边界框重叠，则称边界框为真正的正检测。

    6. 区域建议方法虽然从未应用于词的检测，但在一般对象检测中得到了广泛的关注。

    7. 区域建议方法的目的是生成高召回率的目标区域建议，但代价是大量的假阳性检测。

    8. 即使如此，与检测管道后续阶段的滑动窗口评估相比，这仍然大大减少了搜索空间。有效地将区域建议方法视为弱检测器。

    9. 在本研究中，我们结合了两种检测机制的结果——边缘盒区域建议算法(Zitnick and Dollar 2014, section . 4.1)和弱集通道特征检测器(Dollar et al. 2014, section . 4.2)。

       #### Edge Boxed

       1. 我们使用了Zitnick和Dollar(2014)中描述的边盒公式。
       2. 边缘框背后的关键直觉是，由于对象通常是**自包含**(self contained)的，因此由包围框完全包围的轮廓数表示包含对象的框的可能性。
       3. 边缘往往与对象边界相对应，因此，如果边缘包含在边界框中，这意味着对象包含在边界框中，而越过边界框边界的边缘则表明有一个对象不完全包含在边界框中。
       4. 当需要的对象是单词(具有明显边界的字符的集合)时，对象是边界集合的概念尤其正确。
       5. 在Zitnick和Dollar(2014)之后，我们使用结构化边缘检测器(Dollar和Zitnick 2013, 2014)计算边缘响应ap，并对边缘响应进行正交的非最大值抑制，使边缘映射稀疏化。
       6. 根据完全由b包含的边的数量，并由b的周长标准化，给候选边界框b赋值sb。完整的细节可以在Zitnick和Dollar(2014)中找到。
       7. 盒子b以滑动窗口的方式，在多个尺度和纵横比上进行评估，并给出sb的评分。
       8. 最后，按照分数对盒子进行排序，并进行非最大抑制:当一个盒子与另一个得分较高的盒子重叠超过阈值时，则删除该盒子
       9. 这将产生一组单词Be的候选边界框。

       #### Aggregate Channel Feature Detector

       
